{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNでテキスト分類\n",
    "- word2vecを利用\n",
    "### @colabratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98774,
     "status": "ok",
     "timestamp": 1538217696180,
     "user": {
      "displayName": "Shuto Uchida",
      "photoUrl": "",
      "userId": "06307545447357205044"
     },
     "user_tz": -540
    },
    "id": "i7c7Wco3TXDj",
    "outputId": "fba5dd12-cc1d-4539-878a-6ee716a9420e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libcusparse8.0:amd64.\n",
      "(Reading database ... 18408 files and directories currently installed.)\n",
      "Preparing to unpack .../libcusparse8.0_8.0.61-1_amd64.deb ...\n",
      "Unpacking libcusparse8.0:amd64 (8.0.61-1) ...\n",
      "Selecting previously unselected package libnvrtc8.0:amd64.\n",
      "Preparing to unpack .../libnvrtc8.0_8.0.61-1_amd64.deb ...\n",
      "Unpacking libnvrtc8.0:amd64 (8.0.61-1) ...\n",
      "Selecting previously unselected package libnvtoolsext1:amd64.\n",
      "Preparing to unpack .../libnvtoolsext1_8.0.61-1_amd64.deb ...\n",
      "Unpacking libnvtoolsext1:amd64 (8.0.61-1) ...\n",
      "Setting up libnvtoolsext1:amd64 (8.0.61-1) ...\n",
      "Setting up libcusparse8.0:amd64 (8.0.61-1) ...\n",
      "Setting up libnvrtc8.0:amd64 (8.0.61-1) ...\n",
      "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
      "Collecting cupy-cuda80==4.0.0b4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/f2/7e4770a2a46ac1de3ad379446ff5e3f54eb0606c3aa589d90fab6ffcc007/cupy_cuda80-4.0.0b4-cp36-cp36m-manylinux1_x86_64.whl (205.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 205.4MB 187kB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80==4.0.0b4) (1.11.0)\n",
      "Collecting fastrlock>=0.3 (from cupy-cuda80==4.0.0b4)\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/93/a7efbd39eac46c137500b37570c31dedc2d31a8ff4949fcb90bda5bc5f16/fastrlock-0.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80==4.0.0b4) (1.14.6)\n",
      "Installing collected packages: fastrlock, cupy-cuda80\n",
      "Successfully installed cupy-cuda80-4.0.0b4 fastrlock-0.4\n",
      "Collecting chainer==4.0.0b4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/4f/4507635cc3257964928653ea7aace55dfaa2616e41b5909ecdba2be8ffe9/chainer-4.0.0b4.tar.gz (372kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 13.1MB/s \n",
      "\u001b[?25hCollecting filelock (from chainer==4.0.0b4)\n",
      "  Downloading https://files.pythonhosted.org/packages/85/1c/389ca4da8b631a06dec64c94c9c6f22bbd9be236f0030ee4863e7d6e42a7/filelock-3.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.0.0b4) (1.14.6)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.0.0b4) (3.6.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.0.0b4) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer==4.0.0b4) (39.1.0)\n",
      "Building wheels for collected packages: chainer\n",
      "  Running setup.py bdist_wheel for chainer ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/89/2e/12/fe6441d846a967c24ded700e140bc2a71f56044199b72f33dc\n",
      "Successfully built chainer\n",
      "Installing collected packages: filelock, chainer\n",
      "Successfully installed chainer-4.0.0b4 filelock-3.0.8\n",
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 23.6MB 1.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
      "Collecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
      "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 11.9MB/s \n",
      "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/49/4616f3beaa9974aa275933218fe64b200f4177ff5f0753a3b72c5cec5dda/boto3-1.9.14-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 25.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.24)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 20.1MB/s \n",
      "\u001b[?25hCollecting botocore<1.13.0,>=1.12.14 (from boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/fa/af1ad7aebe166932fe1cac5eae5413d090eca4d723829756c31fc53c174d/botocore-1.12.14-py2.py3-none-any.whl (4.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.7MB 5.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.14->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
      "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.14->boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 22.4MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto-2.49.0 boto3-1.9.14 botocore-1.12.14 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
    "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
    "!pip install cupy-cuda80==4.0.0b4 \n",
    "!pip install chainer==4.0.0b4\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2jKymug1iO_"
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "import codecs\n",
    "from gensim import models\n",
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set(context='talk', style='darkgrid', palette='deep', font='IPAexGothic', font_scale=1, color_codes=False, rc=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1890,
     "status": "ok",
     "timestamp": 1538217815437,
     "user": {
      "displayName": "Shuto Uchida",
      "photoUrl": "",
      "userId": "06307545447357205044"
     },
     "user_tz": -540
    },
    "id": "NYEZgQEeTWYM",
    "outputId": "b08eb697-521a-4ea6-fc7b-0703c17b6ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU availability: True\n",
      "cuDNN availablility: True\n"
     ]
    }
   ],
   "source": [
    "print('GPU availability:', chainer.cuda.available)\n",
    "print('cuDNN availablility:', chainer.cuda.cudnn_enabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ローカルのgoogle driveのマウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28386,
     "status": "ok",
     "timestamp": 1538217843879,
     "user": {
      "displayName": "Shuto Uchida",
      "photoUrl": "",
      "userId": "06307545447357205044"
     },
     "user_tz": -540
    },
    "id": "SnokQHMfWR5T",
    "outputId": "8cd82ba6-2bd6-4445-97e4-69838805e97a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2981,
     "status": "ok",
     "timestamp": 1538047036072,
     "user": {
      "displayName": "Shuto Uchida",
      "photoUrl": "",
      "userId": "06307545447357205044"
     },
     "user_tz": -540
    },
    "id": "GbdFinH3W7cY",
    "outputId": "832094f3-7858-4ec3-e9b2-37908c76b7b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20ng-test-all-terms.txt   20ng-train-no-stop.txt  reuter.txt\n",
      "20ng-test-no-stop.txt\t  r8-test-all-terms.txt   text_reuter1.txt\n",
      "20ng-train-all-terms.txt  r8-train-all-terms.txt  text_reuter.txt\n"
     ]
    }
   ],
   "source": [
    "! ls /content/gdrive/My\\ Drive/Python3/document_classification/text/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9Ldtswf1iPN"
   },
   "outputs": [],
   "source": [
    "#データはReuters 21578（学習とテストを合体させたreuter.txt）\n",
    "\n",
    "ID=[]\n",
    "Document=[]\n",
    "for line in open('./gdrive/My Drive/Python3/document_classification/text/reuter.txt', 'r'):\n",
    "    itemList = line[:-1].split('\\t')\n",
    "    ID.append(itemList[0])\n",
    "    Document.append(itemList[1].split())    \n",
    "\n",
    "DIC = {\"acq\":0,\"crude\":1,\"earn\":2,\"grain\":3,\"interest\":4,\"money-fx\":5,\"ship\":6,\"trade\":7}\n",
    "    \n",
    "label = []\n",
    "for i in ID:\n",
    "    label.append(DIC[i])\n",
    "    \n",
    "ID = np.array(ID)\n",
    "Document = np.array(Document)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXbjr5Ae1iPV"
   },
   "outputs": [],
   "source": [
    "def nomarlize(vector):\n",
    "    X = np.empty((len(vector), len(vector[0])))    \n",
    "    for i, vec in enumerate(vector):\n",
    "        j = vec / np.linalg.norm(vec)\n",
    "        X[i] = j\n",
    "    return X\n",
    "\n",
    "def seikika(model):\n",
    "    WORD_dic = {}\n",
    "    for index, word in enumerate(model.wv.index2word):\n",
    "        WORD_dic.update({word:index})#word & Index\n",
    "\n",
    "    I_wei_norm = model.wv.syn0\n",
    "    O_wei_norm = model.syn1neg\n",
    "    IO_wei_norm = np.c_[model.wv.syn0, model.syn1neg]\n",
    "    new_wei_norm = model.wv.syn0 + model.syn1neg\n",
    "    I_wei_norm = nomarlize(I_wei_norm)\n",
    "    O_wei_norm = nomarlize(O_wei_norm)\n",
    "    IO_wei_norm = nomarlize(IO_wei_norm)\n",
    "    new_wei_norm = nomarlize(new_wei_norm)\n",
    "    \n",
    "    # 単語ベクトル1,2,3,4\n",
    "    return I_wei_norm,O_wei_norm,IO_wei_norm, new_wei_norm, WORD_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acsweACg1iPb"
   },
   "outputs": [],
   "source": [
    "# 学習用文書の生成\n",
    "def gen_text():\n",
    "    wakati = []\n",
    "    for j in X_train:\n",
    "        wakati.append(' '.join(j))\n",
    "    wakati = ' '.join(wakati)\n",
    "    f = codecs.open('./gdrive/My Drive/Python3/document_classification/text/text_reuter1.txt', 'w',\"utf-8\") # 書き込みモードで開く\n",
    "    f.write(wakati) # 引数の文字列をファイルに書き込む\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PiCvFdlQsKGf"
   },
   "outputs": [],
   "source": [
    "# 文書のベクトル化\n",
    "def generate_vec(wei_norm, data):\n",
    "    data_x_vec = []\n",
    "    for sentence in data:\n",
    "        sentence_vec = []\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                if words[word] > cut_num:\n",
    "                    sentence_vec.append(wei_norm[words[word]])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        data_x_vec.append(sentence_vec)\n",
    "        \n",
    "    # 文章の長さを揃えるため、ゼロパディングする\n",
    "    max_sentence_size = 0\n",
    "    for sentence_vec in data_x_vec:\n",
    "        if max_sentence_size < len(sentence_vec):\n",
    "            max_sentence_size = len(sentence_vec)\n",
    "    for sentence_vec in data_x_vec:\n",
    "        while len(sentence_vec) < max_sentence_size:\n",
    "            sentence_vec.append(np.zeros(size))\n",
    "    return data_x_vec, max_sentence_size\n",
    "\n",
    "class SentenceClassifierCNN(chainer.ChainList):\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel, filter_height_list, filter_width, out_size, max_sentence_size):\n",
    "        \"\"\"クラスの初期化\n",
    "        \n",
    "        Args:\n",
    "            in_channel: 入力チャネル数\n",
    "            out_channel: 出力チャネル数\n",
    "            filter_height_list: フィルター縦サイズの配列\n",
    "            filter_width: フィルター横サイズ\n",
    "            out_size: 分類ラベル数\n",
    "            max_sentence_size: 文章の長さの最大サイズ\n",
    "        \"\"\"\n",
    "        self.filter_height_list = filter_height_list\n",
    "        self.max_sentence_size = max_sentence_size\n",
    "        self.convolution_num = len(filter_height_list)\n",
    "        \n",
    "        # Linkの定義\n",
    "        link_list = [L.Convolution2D(in_channel, out_channel, (i, filter_width), pad=0) for i in filter_height_list] # Convolution層用のLinkをフィルター毎に追加\n",
    "        link_list.append(L.Linear(out_channel * self.convolution_num, out_channel * self.convolution_num)) # 隠れ層\n",
    "        link_list.append(L.Linear(out_channel * self.convolution_num, out_size)) # 出力層\n",
    "        \n",
    "        # 定義したLinkのリストを用いてクラスを初期化する\n",
    "        super(SentenceClassifierCNN, self).__init__(*link_list)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"順伝播の計算を行う関数\n",
    "        \n",
    "        Args:\n",
    "            x: 入力値\n",
    "        Returns:\n",
    "            y:\n",
    "        \"\"\"\n",
    "        # フィルタを通した結果を格納する配列\n",
    "        xcs = [None for i in self.filter_height_list]\n",
    "        chs = [None for i in self.filter_height_list]\n",
    "        \n",
    "        # フィルタごとにループ\n",
    "        for i, filter_height in enumerate(self.filter_height_list):\n",
    "            xcs[i] = F.relu(self[i](x))\n",
    "            chs[i] = F.max_pooling_2d(xcs[i], (self.max_sentence_size+1-filter_height))\n",
    "        \n",
    "        # Convolution+Poolingの結果の結合\n",
    "        h = F.concat(chs, axis=2)\n",
    "        h = F.dropout(F.tanh(self[self.convolution_num+0](h)))\n",
    "        y = self[self.convolution_num+1](h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aOEtK0l1iPj"
   },
   "outputs": [],
   "source": [
    "# Word2Vecパラメータ\n",
    "size = 100\n",
    "window = 5\n",
    "negative = 5\n",
    "cut_num = 50 # 出現頻度上位単語の無視"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3148
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5490413,
     "status": "ok",
     "timestamp": 1538229840811,
     "user": {
      "displayName": "Shuto Uchida",
      "photoUrl": "",
      "userId": "06307545447357205044"
     },
     "user_tz": -540
    },
    "id": "jXrzJQPffOkk",
    "outputId": "f3b63acb-f92c-4f46-d498-4a6028dce2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           1.20881     0.829287              0.624839       0.758482                  259.504       \n",
      "\u001b[J     total [######............................................] 13.57%\n",
      "this epoch [###############################...................] 62.89%\n",
      "       100 iter, 1 epoch / 12 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J2           0.624323    0.484818              0.802131       0.853304                  505.033       \n",
      "\u001b[J3           0.366886    0.307542              0.899194       0.923393                  754.621       \n",
      "\u001b[J     total [#############.....................................] 27.15%\n",
      "this epoch [############......................................] 25.79%\n",
      "       200 iter, 3 epoch / 12 epochs\n",
      "   0.24837 iters/sec. Estimated time to finish: 0:36:00.822956.\n",
      "\u001b[4A\u001b[J4           0.243541    0.237157              0.931803       0.924732                  1000.16       \n",
      "\u001b[J     total [####################..............................] 40.72%\n",
      "this epoch [############################################......] 88.68%\n",
      "       300 iter, 4 epoch / 12 epochs\n",
      "   0.24845 iters/sec. Estimated time to finish: 0:29:17.611274.\n",
      "\u001b[4A\u001b[J5           0.183193    0.203555              0.945901       0.941607                  1245.68       \n",
      "\u001b[J6           0.146028    0.177714              0.958226       0.947857                  1495.26       \n",
      "\u001b[J     total [###########################.......................] 54.30%\n",
      "this epoch [#########################.........................] 51.57%\n",
      "       400 iter, 6 epoch / 12 epochs\n",
      "   0.24843 iters/sec. Estimated time to finish: 0:22:35.242061.\n",
      "\u001b[4A\u001b[J7           0.12225     0.164306              0.962295       0.947232                  1740.81       \n",
      "\u001b[J8           0.101317    0.159404              0.971129       0.949732                  1990.38       \n",
      "\u001b[J     total [#################################.................] 67.87%\n",
      "this epoch [#######...........................................] 14.46%\n",
      "       500 iter, 8 epoch / 12 epochs\n",
      "   0.24472 iters/sec. Estimated time to finish: 0:16:07.155625.\n",
      "\u001b[4A\u001b[J9           0.0848108   0.149117              0.975738       0.950357                  2235.94       \n",
      "\u001b[J     total [########################################..........] 81.45%\n",
      "this epoch [######################################............] 77.36%\n",
      "       600 iter, 9 epoch / 12 epochs\n",
      "   0.24843 iters/sec. Estimated time to finish: 0:09:10.166093.\n",
      "\u001b[4A\u001b[J10          0.0720693   0.144502              0.980656       0.950357                  2481.47       \n",
      "\u001b[J11          0.064667    0.135107              0.980807       0.954018                  2731.05       \n",
      "\u001b[J     total [###############################################...] 95.02%\n",
      "this epoch [####################..............................] 40.25%\n",
      "       700 iter, 11 epoch / 12 epochs\n",
      "   0.24842 iters/sec. Estimated time to finish: 0:02:27.652066.\n",
      "\u001b[4A\u001b[J12          0.0537908   0.137686              0.988525       0.957678                  2976.6        \n",
      "\u001b[J1\n",
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           1.16834     0.755368              0.640322       0.759732                  249.725       \n",
      "\u001b[J     total [######............................................] 13.57%\n",
      "this epoch [###############################...................] 62.89%\n",
      "       100 iter, 1 epoch / 12 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J2           0.56396     0.451138              0.818361       0.873482                  495.292       \n",
      "\u001b[J3           0.353117    0.305084              0.901452       0.923303                  744.88        \n",
      "\u001b[J     total [#############.....................................] 27.15%\n",
      "this epoch [############......................................] 25.79%\n",
      "       200 iter, 3 epoch / 12 epochs\n",
      "   0.24836 iters/sec. Estimated time to finish: 0:36:00.914921.\n",
      "\u001b[4A\u001b[J4           0.24138     0.233866              0.933607       0.927768                  990.439       \n",
      "\u001b[J     total [####################..............................] 40.72%\n",
      "this epoch [############################################......] 88.68%\n",
      "       300 iter, 4 epoch / 12 epochs\n",
      "   0.24843 iters/sec. Estimated time to finish: 0:29:17.743142.\n",
      "\u001b[4A\u001b[J5           0.184163    0.200424              0.947869       0.928571                  1236.01       \n",
      "\u001b[J6           0.148502    0.178947              0.955161       0.939643                  1485.6        \n",
      "\u001b[J     total [###########################.......................] 54.30%\n",
      "this epoch [#########################.........................] 51.57%\n",
      "       400 iter, 6 epoch / 12 epochs\n",
      "    0.2484 iters/sec. Estimated time to finish: 0:22:35.369646.\n",
      "\u001b[4A\u001b[J7           0.124267    0.16808               0.965902       0.944643                  1731.18       \n",
      "\u001b[J8           0.106943    0.156144              0.967419       0.947768                  1980.76       \n",
      "\u001b[J     total [#################################.................] 67.87%\n",
      "this epoch [#######...........................................] 14.46%\n",
      "       500 iter, 8 epoch / 12 epochs\n",
      "    0.2447 iters/sec. Estimated time to finish: 0:16:07.241433.\n",
      "\u001b[4A\u001b[J9           0.0896633   0.152435              0.975246       0.950893                  2226.3        \n",
      "\u001b[J     total [########################################..........] 81.45%\n",
      "this epoch [######################################............] 77.36%\n",
      "       600 iter, 9 epoch / 12 epochs\n",
      "   0.24842 iters/sec. Estimated time to finish: 0:09:10.204707.\n",
      "\u001b[4A\u001b[J10          0.0742598   0.143914              0.98           0.950268                  2471.86       \n",
      "\u001b[J11          0.0643919   0.138292              0.983226       0.954018                  2721.41       \n",
      "\u001b[J     total [###############################################...] 95.02%\n",
      "this epoch [####################..............................] 40.25%\n",
      "       700 iter, 11 epoch / 12 epochs\n",
      "   0.24841 iters/sec. Estimated time to finish: 0:02:27.659474.\n",
      "\u001b[4A\u001b[J12          0.0577383   0.139725              0.984262       0.958303                  2966.96       \n",
      "\u001b[J0\n",
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           1.18677     0.744624              0.642258       0.773824                  247.901       \n",
      "\u001b[J     total [######............................................] 13.57%\n",
      "this epoch [###############################...................] 62.87%\n",
      "       100 iter, 1 epoch / 12 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J2           0.597038    0.409312              0.813115       0.886949                  491.603       \n",
      "\u001b[J3           0.352672    0.266272              0.896451       0.923824                  739.293       \n",
      "\u001b[J     total [#############.....................................] 27.14%\n",
      "this epoch [############......................................] 25.73%\n",
      "       200 iter, 3 epoch / 12 epochs\n",
      "   0.25025 iters/sec. Estimated time to finish: 0:35:45.079809.\n",
      "\u001b[4A\u001b[J4           0.240757    0.199613              0.929836       0.947537                  983.027       \n",
      "\u001b[J     total [####################..............................] 40.72%\n",
      "this epoch [############################################......] 88.60%\n",
      "       300 iter, 4 epoch / 12 epochs\n",
      "   0.25031 iters/sec. Estimated time to finish: 0:29:05.032911.\n",
      "\u001b[4A\u001b[J5           0.180741    0.158209              0.951639       0.958162                  1226.76       \n",
      "\u001b[J6           0.148732    0.140681              0.957581       0.956287                  1474.49       \n",
      "\u001b[J     total [###########################.......................] 54.29%\n",
      "this epoch [#########################.........................] 51.47%\n",
      "       400 iter, 6 epoch / 12 epochs\n",
      "   0.25028 iters/sec. Estimated time to finish: 0:22:25.704448.\n",
      "\u001b[4A\u001b[J7           0.120942    0.13426               0.968689       0.955037                  1718.21       \n",
      "\u001b[J8           0.103174    0.112743              0.972097       0.958787                  1965.9        \n",
      "\u001b[J     total [#################################.................] 67.86%\n",
      "this epoch [#######...........................................] 14.33%\n",
      "       500 iter, 8 epoch / 12 epochs\n",
      "   0.24655 iters/sec. Estimated time to finish: 0:16:00.456787.\n",
      "\u001b[4A\u001b[J9           0.089916    0.108027              0.975574       0.960037                  2209.59       \n",
      "\u001b[J     total [########################################..........] 81.43%\n",
      "this epoch [######################################............] 77.20%\n",
      "       600 iter, 9 epoch / 12 epochs\n",
      "    0.2503 iters/sec. Estimated time to finish: 0:09:06.544379.\n",
      "\u001b[4A\u001b[J10          0.0753296   0.102355              0.98           0.962537                  2453.26       \n",
      "\u001b[J11          0.0673263   0.0975381             0.981774       0.964412                  2700.96       \n",
      "\u001b[J     total [###############################################...] 95.01%\n",
      "this epoch [####################..............................] 40.07%\n",
      "       700 iter, 11 epoch / 12 epochs\n",
      "   0.25029 iters/sec. Estimated time to finish: 0:02:27.027264.\n",
      "\u001b[4A\u001b[J12          0.0566058   0.0959461             0.987049       0.961912                  2944.67       \n",
      "\u001b[J1\n",
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           1.14639     0.69375               0.656129       0.789485                  247.901       \n",
      "\u001b[J     total [######............................................] 13.57%\n",
      "this epoch [###############################...................] 62.87%\n",
      "       100 iter, 1 epoch / 12 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J2           0.578365    0.415419              0.815738       0.888824                  491.606       \n",
      "\u001b[J3           0.368471    0.277386              0.893065       0.923824                  739.318       \n",
      "\u001b[J     total [#############.....................................] 27.14%\n",
      "this epoch [############......................................] 25.73%\n",
      "       200 iter, 3 epoch / 12 epochs\n",
      "   0.25024 iters/sec. Estimated time to finish: 0:35:45.149918.\n",
      "\u001b[4A\u001b[J4           0.260545    0.207081              0.924754       0.938824                  983.02        \n",
      "\u001b[J     total [####################..............................] 40.72%\n",
      "this epoch [############################################......] 88.60%\n",
      "       300 iter, 4 epoch / 12 epochs\n",
      "   0.25032 iters/sec. Estimated time to finish: 0:29:04.977409.\n",
      "\u001b[4A\u001b[J5           0.199172    0.180249              0.941311       0.942537                  1226.73       \n",
      "\u001b[J6           0.15944     0.15097               0.953065       0.951287                  1474.43       \n",
      "\u001b[J     total [###########################.......................] 54.29%\n",
      "this epoch [#########################.........................] 51.47%\n",
      "       400 iter, 6 epoch / 12 epochs\n",
      "   0.25029 iters/sec. Estimated time to finish: 0:22:25.632453.\n",
      "\u001b[4A\u001b[J7           0.131624    0.135097              0.962295       0.953787                  1718.14       \n",
      "\u001b[J8           0.11104     0.122921              0.969516       0.954412                  1965.83       \n",
      "\u001b[J     total [#################################.................] 67.86%\n",
      "this epoch [#######...........................................] 14.33%\n",
      "       500 iter, 8 epoch / 12 epochs\n",
      "   0.24656 iters/sec. Estimated time to finish: 0:16:00.420225.\n",
      "\u001b[4A\u001b[J9           0.0937654   0.126825              0.973443       0.951875                  2209.54       \n",
      "\u001b[J     total [########################################..........] 81.43%\n",
      "this epoch [######################################............] 77.20%\n",
      "       600 iter, 9 epoch / 12 epochs\n",
      "    0.2503 iters/sec. Estimated time to finish: 0:09:06.535030.\n",
      "\u001b[4A\u001b[J10          0.0850407   0.112004              0.977049       0.958787                  2453.26       \n",
      "\u001b[J11          0.0693844   0.108075              0.982258       0.961875                  2700.97       \n",
      "\u001b[J     total [###############################################...] 95.01%\n",
      "this epoch [####################..............................] 40.07%\n",
      "       700 iter, 11 epoch / 12 epochs\n",
      "   0.25029 iters/sec. Estimated time to finish: 0:02:27.028103.\n",
      "\u001b[4A\u001b[J12          0.0633287   0.108321              0.98459        0.96                      2944.67       \n",
      "\u001b[J"
     ]
    }
   ],
   "source": [
    "# 5分割交差検証\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "n = 0\n",
    "for train_index, test_index in kf.split(Document):\n",
    "    if n <= 2:\n",
    "        print(n)\n",
    "        n += 1\n",
    "        continue\n",
    "    X_train, X_test = Document[train_index], Document[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #ID_train, ID_test = ID[train_index], ID[test_index]\n",
    "\n",
    "    gen_text()\n",
    "    gc.collect()\n",
    "    \n",
    "    sentences = word2vec.Text8Corpus('./gdrive/My Drive/Python3/document_classification/text/text_reuter1.txt')\n",
    "    #learning\n",
    "    model = word2vec.Word2Vec(sentences, size=size, min_count=5, window=window,\n",
    "                              workers=8, sg = 1, seed = None,iter=15, negative=negative)\n",
    "    \n",
    "    I_wei_norm,O_wei_norm,IO_wei_norm,new_wei_norm, words= seikika(model)\n",
    "    del model, O_wei_norm,IO_wei_norm\n",
    "    gc.collect()\n",
    "    WEI = [I_wei_norm, new_wei_norm]\n",
    "    for index in range(len(WEI)):\n",
    "        # データセット\n",
    "        data_x_vec, max_sentence_size = generate_vec(WEI[index], Document)\n",
    "        data_x_vec = np.array(data_x_vec, dtype=\"float32\")\n",
    "        data_t = np.array(label, dtype=\"int32\")\n",
    "\n",
    "\n",
    "        train_dataset = []\n",
    "        for x, t in zip(data_x_vec[train_index], data_t[train_index]):\n",
    "            train_dataset.append((x.reshape(1, max_sentence_size, size), t))\n",
    "        test_dataset = []\n",
    "        for x, t in zip(data_x_vec[test_index], data_t[test_index]):\n",
    "            test_dataset.append((x.reshape(1, max_sentence_size, size), t))\n",
    "\n",
    "        gpu = 0\n",
    "\n",
    "        # 定数\n",
    "        epoch_num = 12\n",
    "        batch_size = 100\n",
    "        out_size = 8\n",
    "        filter_height_list = [1,2,3]\n",
    "        out_channel = 32\n",
    "\n",
    "        # モデルの定義\n",
    "        model = L.Classifier(SentenceClassifierCNN(\n",
    "            in_channel=1,\n",
    "            out_channel=out_channel,\n",
    "            filter_height_list=filter_height_list,\n",
    "            filter_width=size,\n",
    "            out_size=out_size,\n",
    "            max_sentence_size=max_sentence_size\n",
    "        ))\n",
    "\n",
    "        optimizer = chainer.optimizers.Adam()\n",
    "        optimizer.setup(model)\n",
    "\n",
    "        if gpu >= 0:\n",
    "            chainer.cuda.get_device(gpu).use()\n",
    "            model.to_gpu(gpu)\n",
    "\n",
    "        train = train_dataset\n",
    "        test = test_dataset\n",
    "        train_iter = chainer.iterators.SerialIterator(train, batch_size)\n",
    "        test_iter = chainer.iterators.SerialIterator(test, batch_size, repeat=False, shuffle=False)\n",
    "        updater = chainer.training.StandardUpdater(train_iter, optimizer, device=gpu)\n",
    "        trainer = chainer.training.Trainer(updater, (epoch_num, \"epoch\"), out=\"result\")\n",
    "        trainer.extend(extensions.Evaluator(test_iter, model, device=gpu))\n",
    "        trainer.extend(extensions.LogReport(trigger=(1, \"epoch\")))\n",
    "        trainer.extend(extensions.ProgressBar()) # プログレスバー出力\n",
    "        trainer.extend(extensions.PrintReport( [\"epoch\", \"main/loss\", \"validation/main/loss\", \"main/accuracy\", \"validation/main/accuracy\", \"elapsed_time\"]))\n",
    "        print(index)\n",
    "        trainer.run()\n",
    "        del model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_reuter_C.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
